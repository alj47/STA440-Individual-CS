---
title: "Individual CS"
author: "Austin Jia"
date: "11/28/2019"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### Libraries

```{r, echo = FALSE, include = FALSE}
# Installing packages
pkgTest <- function(x) {
  if (!require(x,character.only = TRUE)) {
    install.packages(x,dep=TRUE)
  }
}
pkgs <- c("jsonlite", "dplyr", "rvest", "purrr", "ggplot2", "gganimate", "ggthemes", "lubridate", "zoo", "shiny", "stringr", "mice", "VIM", "parallel", "corrplot", "MASS", "caTools", "nnet", "randomForest", "pROC", "caret", "ggpubr", "shiny")
for (pkg in pkgs) {
  pkgTest(pkg)
}
```

```{r, include=FALSE, echo = FALSE}
library(jsonlite)
library(dplyr)
library(rvest)
library(purrr)
library(ggplot2)
library(gganimate)
library(ggthemes)
library(lubridate)
library(zoo)
library(shiny)
library(stringr)
library(mice)
library(VIM)
library(parallel)
library(corrplot)
library(MASS)
library(caTools)
library(nnet)
library(randomForest)
library(pROC)
library(caret)
library(ggpubr)
library(shiny)
```

### Scraping
### Page by page method

```{r}
base_url = "https://data.cityofnewyork.us/Education/2016-2017-School-Quality-Report-Results-for-High-S/ewhs-k7um/data"
p = read_html(base_url)

school_quality = tibble(
  "Student Achievement Rating" = base_url %>%
    html_nodes("td:nth-child(11) div") %>%
    html_text()
) 

school_quality
```


### Yellow Pages Method

```{r}
count = 0

for(numPage in 1:2){

        # Create and read the page address
        page = paste('https://data.cityofnewyork.us/Education/2016-2017-School-Quality-Report-Elem-Middle-K-8-Sc/9n2i-9h9s/data/?page', '=', numPage)
        nPage <- str_replace_all(page, pattern=" ", repl="")

        # Read the 20 items of each the page
        for(numItem in 1:3){

                print(paste(' -- Reading the item', numItem, ' on page', numPage))

                item =  paste('item', numItem, sep = "", collapse = NULL)
                xPath <- paste("//*[@id=',item, ']", sep = "'", collapse = NULL)

                # read the path
                readPath <- nPage %>% read_html() %>% html_nodes(xpath = xPath)

                # Get values
                student_achievement_rating  <- readPath %>% html_nodes(".table-responsive:nth-child(7) td:nth-child(11) div") %>% html_text(trim = TRUE)
                
                print(student_achievement_rating)
                
                lengthStudentachievementrating <- length(student_achievement_rating)
                
                print(lengthStudentachievementrating)

                enrollment <- readPath %>% html_nodes("td:nth-child(4) div") %>% html_text(trim = TRUE)
                lengthEnrollment <- length(enrollment)

                school_type <- readPath %>% html_nodes("td:nth-child(3) div") %>% html_text(trim = TRUE)
                lengthSchooltype <- length(school_type)

                if(lengthStudentachievementrating == 0){

                        student_achievement_rating = 'NA'

                }

                if(lengthEnrollment == 0){

                        enrollment = 'NA'

                }

                if(lengthSchooltype == 0){

                        school_type = 'NA'

                }

                # Store variables
                if(count == 0){

                        vectorStudentachievementrating <- student_achievement_rating
                        vectorEnrollment <- enrollment
                        vectorSchooltype <- school_type
                }else{

                        vectorStudentachievementrating <- c(vectorStudentachievementrating, student_achievement_rating)
                        vectorEnrollment <- c(vectorEnrollment, enrollment)
                        vectorSchooltype <- c(vectorSchooltype, school_type)

                }


                count = count + 1

        }


}


df <- data.frame(vectorStudentachievementrating, vectorEnrollment, vectorSchooltype)

df
```

### Data Cleaning

```{r}
data <- read.csv("schooldata.csv")

#Renaming variable names
data = data %>% 
  rename(
    Instruction.Rating = Rigorous.Instruction.Rating,
    Teachers.Rating = Collaborative.Teachers.Rating,
    Leadership.Rating = Effective.School.Leadership.Rating,
    Community.Ties.Rating = Strong.Family.Community.Ties.Rating,
    Instruction.Rating.pct = Rigorous.Instruction...Percent.Positive,
    Teachers.Rating.pct = Collaborative.Teachers...Percent.Positive,
    Supportive.Environment.pct = Supportive.Environment...Percent.Positive,
    Leadership.Rating.pct = Effective.School.Leadership...Percent.Positive,
    Community.Ties.Rating.pct = Strong.Family.Community.Ties...Percent.Positive,
    Challenging.Curriculum.qr = Quality.Review...How.interesting.and.challenging.is.the.curriculum.,
    Effective.Teaching.qr = Quality.Review...How.effective.is.the.teaching.and.learning.,
    School.Assess.qr = Quality.Review...How.well.does.the.school.assess.what.students.are.learning.,
    Expectations.Communicated.qr = Quality.Review...How.clearly.are.high.expectations.communicated.to.students.and.staff.,
    Teachers.Cooperation.qr = Quality.Review...How.well.do.teachers.work.with.each.other.,
    Safe.Inclusive.qr = Quality.Review...How.safe.and.inclusive.is.the.school.while.supporting.social.emotional.growth.,
    Resource.Allocation.qr = Quality.Review...How.well.does.the.school.allocate.and.manage.resources.,
    Meet.Goals.qr = Quality.Review...How.well.does.the.school.identify..track..and.meet.its.goals.,
    Teacher.Development.qr = Quality.Review...How.thoughtful.is.the.school.s.approach.to.teacher.development.and.evaluation.,
    Decisions.Evaluated.qr = Quality.Review...How.well.are.school.decisions.evaluated.and.adjusted.,
    Review.Dates.qr = Quality.Review...Dates.of.Review,
    ELA.Proficiency = Average.Grade.8.English.Proficiency,
    Math.Proficiency = Average.Grade.8.Math.Proficiency,
    Principal.Experience.yrs = Years.of.principal.experience.at.this.school, 
    Teachers.3yrs.Experience = Percent.of.teachers.with.3.or.more.years.of.experience,
    Students.Chronically.Absent = Percent.of.Students.Chronically.Absent
    )


#Replacing blank levels with NAs
data <- data %>% mutate_if(is.factor, list(~factor(replace(., .=="", NA))))
```


```{r}
# Response Variable
data$Student.Achievement.Rating <- factor(data$Student.Achievement.Rating,levels = c("Not Meeting Target", "Approaching Target", "Meeting Target", "Exceeding Target", "NA"))

g0 = ggplot(data, aes(factor(Student.Achievement.Rating),fill = Student.Achievement.Rating)) +
geom_bar(stat="count", position = "dodge") + 
scale_fill_brewer(palette = "Set1") + ggtitle("Student Achievement Rating Distribution") + xlab("Student Achievement Rating") + labs(fill = "Target Category") + theme(axis.text.x=element_text(angle=45, hjust=1))
g0

#Combining Factor Levels
levels(data$Student.Achievement.Rating) <- list("Not Meeting Target"=c("Not Meeting Target", "Approaching Target"), "Meeting Target"=c("Meeting Target", "Exceeding Target"))
```

I merged the four response categories of "Not Meeting Target", "Approaching Target", "Meeting Target", and "Exceeding Target" into a binary "Not Meeting Target" and "Meeting Target". I did this for a couple reasons. First, this simplifies the classification problem down from multinomial logistic regression to binary logistic regression, which features simpler interpretations. Second, "Not Meeting Target" only had 39 occurences; with so many predictors, my model would surely have low power. Finally, while it is nice to have a gradient of exceptional to mediocre schools, from a policymaker's perspective, it is more expedient to allocate a budget to all schools that fall below a certain threshold. 

```{r}
#Explanatory Variables

#Collinearity Matrix
data_numeric = data[ , purrr::map_lgl(data, is.numeric)]
corrplot(cor(data_numeric, use="pairwise.complete.obs"), method = "circle", tl.cex=0.5)

#Removing Covariates
redundant_cols = c("Instruction.Rating", "Supportive.Environment.Rating", "Community.Ties.Rating", "Teachers.Rating", "Leadership.Rating", "Trust.Rating", "DBN", "Percent.HRA.Eligible", "Effective.Teaching.qr", "Expectations.Communicated.qr", "Safe.Inclusive.qr", "Meet.Goals.qr", "Decisions.Evaluated.qr", "Challenging.Curriculum.qr", "School.Assess.qr", "Teachers.Cooperation.qr", "Resource.Allocation.qr", "Teacher.Development.qr", "Review.Dates.qr", "Students.Chronically.Absent", "Percent.in.Temp.Housing", "School.Type", "ELA.Proficiency", "Math.Proficiency")
data = data[ , -which(names(data) %in% redundant_cols)]
colnames(data)
```

I decided to remove the above covariates for a couple reasons. First, as the correlation matrix demonstrates, there is high correlation between several rating metrics and economic need proxies, so I eliminated all but one to address collinearity and reduce variance. For example, Supportive.Environment.Rating and Supportive.Environment.Rating.pct measure the same metric in different formats, and percent in temporary housing and percent HRA elgible are both proxies for economic need. Second, as the regression "one-in-ten" rule-of-thumb dictates, I should have at most one predictor for every 10 response-variable combinations. Third, I removed all the Quality Review covariates because (1) they are likely highly correlated with each other, (2) the data dictionary does not define what constitutes such subjective evaluation metrics, and (3) these metrics are likely highly inconsistent from school to school, so I felt that they did not add much value to the model.

### Missing Data

```{r}
sum(is.na(data)) / (dim(data)[1] * dim(data)[2])
nrow(data[complete.cases(data), ])
nrow(data[complete.cases(data), ])/nrow(data)
```

```{r}
missing.prop <- apply(data, MARGIN = 2, FUN = function(x) { sum(is.na(x)) })
missing.prop <- missing.prop / dim(data)[1]
missing.prop <- data.frame("prop" = missing.prop,
                           "var" = names(data))
ggplot(missing.prop, aes(x = reorder(var, -prop), y = prop)) + 
  geom_bar(stat = "identity") +
  theme(axis.text.x=element_text(angle=90,hjust=1,vjust=0.5)) + 
  geom_col(colour = "black", fill = "#FF6666") + 
  xlab("Covariate") + 
  ylab("Proportion Missing") +
  ggtitle("The Proportion of Missing Values for Each Covariate")

sum(is.na(data$Student.Achievement.Rating))/nrow(data)
```

Some initial data exploration tells us that our data is missing about 2% of its values. That 2% missing data is distributed in such a way that only 84% of our observations (406 schools) have complete information. The plot showcases some of the most problematic covariates in terms of missing data. 

```{r}
#Not MCAR
marginplot(data[, c("Teacher.Attendance.Rate", "Teachers.3yrs.Experience")], col = mdc(1:2), cex.numbers = 1.2, pch = 19)
```

Looking at the distributions, we can see that the missngness of Teacher Attendance and Teacher Experience seem dependent, indicating that the covariates are not MCAR. This could be because when teachers are absent during data collection days, then teacher experience may not be collected. Given the fact that our sample size is already so limited, I decided to use Multiple Imputation methods instead of tossing out valuable information. 

```{r, include=FALSE}
#Mean and Mode Imputation 

calc.mode <- function(x) {
  ux <- na.omit(unique(x))
  ux[which.max(tabulate(match(x, ux)))]
}
impute_covariates <- as.character(missing.prop[(missing.prop$prop <= 0.05) & (missing.prop$prop > 0), ]$var)
data2 <- as.data.frame(data)
for (var in impute_covariates) {
  print(var)
  if (is.factor(data2[[var]])) {
    data2[is.na(data2[[var]]), var] <- calc.mode(data2[[var]])
  } else {
    data2[is.na(data[[var]]), var] <- mean(data[[var]], na.rm = TRUE)
  }
}
```

We used MICE, or Multiple Imputation using Chained Equations, to created our imputed datasets. We created 4 imputed datasets, roughly corresponding to the percent of missing data. 

```{r, include=FALSE}
set.seed(123)

data2$Student.Achievement.Rating.num = data2$Student.Achievement.Rating
levels(data2$Student.Achievement.Rating.num) <- c(0, 1)
data2$Student.Achievement.Rating.num
data_imputer = subset(data2, select = -c(School.Name, Student.Achievement.Rating))

if (!file.exists("mice.rds")) {
   start_time <- Sys.time()
   data3 <- parlmice(data_imputer, m=4, printFlag=FALSE, maxit = 5,
                   cluster.seed=333, n.core = 2, n.imp.core = 2, cl.type = "FORK")
   end_time <- Sys.time()
   end_time - start_time
 } else {
   data3 <- readRDS("mice.rds")
 }

data4 = data3$data
data4$Student.Achievement.Rating = data4$Student.Achievement.Rating.num
levels(data4$Student.Achievement.Rating) <- c("Not Meeting Target", "Meeting Target")

data5 = na.omit(data4)

#Gradual whittling down of NAs
colnames(data)[colSums(is.na(data)) > 0]
colnames(data2)[colSums(is.na(data2)) > 0]
```

### Visualizations to be used in shiny

```{r}
#Response Variable
p_sar = ggplot(data5, aes(factor(Student.Achievement.Rating),fill = Student.Achievement.Rating)) +
geom_bar(stat="count", position = "dodge") + 
scale_fill_brewer(palette = "Set1") + ggtitle("Student Achievement Rating Distribution") + xlab("Student Achievement Rating") + labs(fill = "Target Category") + theme(axis.text.x=element_text(angle=45, hjust=1))

#Enrollment
p_enrollment = ggplot(data5,aes(x=Enrollment,fill=factor(Student.Achievement.Rating)))+geom_density(alpha=0.25)+
  geom_vline(aes(xintercept=mean(Enrollment[Student.Achievement.Rating=="Not Meeting Target"],na.rm=T)),color="red",linetype="dashed",lwd=1)+
  geom_vline(aes(xintercept=mean(Enrollment[Student.Achievement.Rating=="Meeting Target"],na.rm=T)),color="green",linetype="dashed",lwd=1)+
  scale_x_continuous(breaks = seq(8,15,1))+
  xlab(label = "Enrollment")+
  ggtitle("Distribution of Enrollment")+
  theme_classic() + labs(fill = "Student Achievement Rating")

#Racial Breakdown
p_asian = ggplot(data5,aes(x=Percent.Asian,fill=factor(Student.Achievement.Rating)))+geom_density(alpha=0.25)+
  geom_vline(aes(xintercept=mean(Percent.Asian[Student.Achievement.Rating=="Not Meeting Target"],na.rm=T)),color="red",linetype="dashed",lwd=1)+
  geom_vline(aes(xintercept=mean(Percent.Asian[Student.Achievement.Rating=="Meeting Target"],na.rm=T)),color="green",linetype="dashed",lwd=1)+
  scale_x_continuous(breaks = seq(8,15,1))+
  xlab(label = "Percent Asian")+
  ggtitle("Distribution of Percentage Asian")+
  theme_classic() + labs(fill = "Student Achievement Rating")

p_hispanic = ggplot(data5,aes(x=Percent.Hispanic,fill=factor(Student.Achievement.Rating)))+geom_density(alpha=0.25)+
  geom_vline(aes(xintercept=mean(Percent.Hispanic[Student.Achievement.Rating=="Not Meeting Target"],na.rm=T)),color="red",linetype="dashed",lwd=1)+
  geom_vline(aes(xintercept=mean(Percent.Hispanic[Student.Achievement.Rating=="Meeting Target"],na.rm=T)),color="green",linetype="dashed",lwd=1)+
  scale_x_continuous(breaks = seq(8,15,1))+
  xlab(label = "Percent Hispanic")+
  ggtitle("Distribution of Percentage Hispanic")+
  theme_classic()+ labs(fill = "Student Achievement Rating")

p_black = ggplot(data5,aes(x=Percent.Black,fill=factor(Student.Achievement.Rating)))+geom_density(alpha=0.25)+
  geom_vline(aes(xintercept=mean(Percent.Black[Student.Achievement.Rating=="Not Meeting Target"],na.rm=T)),color="red",linetype="dashed",lwd=1)+
  geom_vline(aes(xintercept=mean(Percent.Black[Student.Achievement.Rating=="Meeting Target"],na.rm=T)),color="green",linetype="dashed",lwd=1)+
  scale_x_continuous(breaks = seq(8,15,1))+
  xlab(label = "Percent Black")+
  ggtitle("Distribution of Percentage Black")+
  theme_classic()+ labs(fill = "Student Achievement Rating")

p_white = ggplot(data5,aes(x=Percent.White,fill=factor(Student.Achievement.Rating)))+geom_density(alpha=0.25)+
  geom_vline(aes(xintercept=mean(Percent.White[Student.Achievement.Rating=="Not Meeting Target"],na.rm=T)),color="red",linetype="dashed",lwd=1)+
  geom_vline(aes(xintercept=mean(Percent.White[Student.Achievement.Rating=="Meeting Target"],na.rm=T)),color="green",linetype="dashed",lwd=1)+
  scale_x_continuous(breaks = seq(8,15,1))+
  xlab(label = "Percent Asian")+
  ggtitle("Distribution of Percentage Asian")+
  theme_classic()+ labs(fill = "Student Achievement Rating")

#Faculty Experience
p_principal_exp = ggplot(data5,aes(x=Principal.Experience.yrs,fill=factor(Student.Achievement.Rating)))+geom_density(alpha=0.25)+
  geom_vline(aes(xintercept=mean(Principal.Experience.yrs[Student.Achievement.Rating=="Not Meeting Target"],na.rm=T)),color="red",linetype="dashed",lwd=1)+
  geom_vline(aes(xintercept=mean(Principal.Experience.yrs[Student.Achievement.Rating=="Meeting Target"],na.rm=T)),color="green",linetype="dashed",lwd=1)+
  scale_x_continuous(breaks = seq(8,15,1))+
  xlab(label = "Principal Experience (yrs)")+
  ggtitle("Distribution of Principal Experience")+
  theme_classic()+ labs(fill = "Student Achievement Rating")

p_teacher_exp = ggplot(data5,aes(x=Teachers.3yrs.Experience,fill=factor(Student.Achievement.Rating)))+geom_density(alpha=0.25)+
  geom_vline(aes(xintercept=mean(Teachers.3yrs.Experience[Student.Achievement.Rating=="Not Meeting Target"],na.rm=T)),color="red",linetype="dashed",lwd=1)+
  geom_vline(aes(xintercept=mean(Teachers.3yrs.Experience[Student.Achievement.Rating=="Meeting Target"],na.rm=T)),color="green",linetype="dashed",lwd=1)+
  scale_x_continuous(breaks = seq(8,15,1))+
  xlab(label = "Teacher Experience (% More than 3 yrs)")+
  ggtitle("Distribution of Teacher Experience")+
  theme_classic()+ labs(fill = "Student Achievement Rating")

#Financial Circumstances
p_econ = ggplot(data5,aes(x=Economic.Need.Index,fill=factor(Student.Achievement.Rating)))+geom_density(alpha=0.25)+
  geom_vline(aes(xintercept=mean(Economic.Need.Index[Student.Achievement.Rating=="Not Meeting Target"],na.rm=T)),color="red",linetype="dashed",lwd=1)+
  geom_vline(aes(xintercept=mean(Economic.Need.Index[Student.Achievement.Rating=="Meeting Target"],na.rm=T)),color="green",linetype="dashed",lwd=1)+
  scale_x_continuous(breaks = seq(8,15,1))+
  xlab(label = "Economic Need Index")+
  ggtitle("Distribution of Economic Need Index")+
  theme_classic()+ labs(fill = "Student Achievement Rating")

#Ratings
p_instruction_rating = ggplot(data5,aes(x=Instruction.Rating.pct,fill=factor(Student.Achievement.Rating)))+geom_density(alpha=0.25)+
  geom_vline(aes(xintercept=mean(Instruction.Rating.pct[Student.Achievement.Rating=="Not Meeting Target"],na.rm=T)),color="red",linetype="dashed",lwd=1)+
  geom_vline(aes(xintercept=mean(Instruction.Rating.pct[Student.Achievement.Rating=="Meeting Target"],na.rm=T)),color="green",linetype="dashed",lwd=1)+
  scale_x_continuous(breaks = seq(8,15,1))+
  xlab(label = "% Approval of Instruction Rating")+
  ggtitle("Distribution of Instruction Rating Approval")+
  theme_classic()+ labs(fill = "Student Achievement Rating")
```


### Modeling

```{r}
# Split dataset into training set, validation set, and test set

splitSample <- sample(1:2, size = nrow(data2), prob = c(0.7, 0.3), 
    replace = T)

# training set
train_set <- na.omit(data2[splitSample == 1, ])  # 397 observations

intrain <- sample(1:2, size = nrow(train_set), prob = c(0.7, 0.3), replace = T)

train <- train_set[intrain == 1, ]  # 277 observations

# validation set
valid <- train_set[intrain == 2, ]  # 120 observations

# test set
test <- na.omit(data2[splitSample == 2, ])  # 172 observations

#Cross Validation method
cv <- trainControl(method = "cv", number = 10)
set.seed(1234)
```

```{R}
# Logisitic Regression
glm.fit.model = glm(Student.Achievement.Rating ~ Enrollment + Percent.Asian + Percent.Black + Economic.Need.Index + Principal.Experience.yrs + Teachers.Rating.pct, data = train, family = binomial)
glm.fit.pred <- train(Student.Achievement.Rating ~ Enrollment + Percent.Asian + Percent.Black + Economic.Need.Index + Principal.Experience.yrs + Teachers.Rating.pct, data = train, method = "glm", family = binomial, 
    trControl = cv)
summary(glm.fit.model)

# Random Forest
rf.fit.model <- randomForest(Student.Achievement.Rating ~ Percent.Asian + Enrollment + Economic.Need.Index, data = train, ntree = 100, 
    importance = TRUE)
rf.fit.pred <- train(Student.Achievement.Rating ~ Enrollment + Percent.Asian + Percent.Black + Economic.Need.Index + Principal.Experience.yrs + Teachers.Rating.pct, data = train, method = "rf", ntree = 100, 
    importance = TRUE, trControl = cv)
summary(rf.fit.model)
varImpPlot(rf.fit.model)
```

```{r}
#Predictions on Validation Set and Confusion Matrices
# Logistic Regression
pred.glm <- predict(glm.fit.pred, valid)
# Random Forest
pred.rf <- predict(rf.fit.pred, valid)
# Logisitic Regression
cm.glm <- confusionMatrix(valid$Student.Achievement.Rating, pred.glm)
# Random Forest
cm.rf <- confusionMatrix(valid$Student.Achievement.Rating, pred.rf)
```

```{r}
#Tabulating Results
Model <- c("Logistic regression", "Random forest")  # vector containing names of models

# Training classification accuracy
TrainAccuracy <- c(max(glm.fit.pred$results$Accuracy), max(rf.fit.pred$results$Accuracy))

# Training misclassification error
Train_missclass_Error <- 1 - TrainAccuracy

# validation classification accuracy
ValidationAccuracy <- c(cm.glm$overall[1], 
    cm.rf$overall[1])

# Validation misclassification error or out-of-sample-error
Validation_missclass_Error <- 1 - ValidationAccuracy

metrics <- data.frame(Model, TrainAccuracy, Train_missclass_Error, ValidationAccuracy, 
    Validation_missclass_Error) 

knitr::kable(metrics, digits = 5) 

#Prediction on test set
pred.test.glm <- predict(glm.fit.pred, test)
pred.test.glm
pred.test.rf <- predict(rf.fit.pred, test)
pred.test.rf
```

### Model Selection

Misclassification error is 36% for logistic regression and 41% for random forest. The logistic regression is also easier to interpret. For these reasons, we move ahead with the logistic regression. 

### Model Specification

$$
\mbox{logit}(Pr(y_i = 1)) = \beta_0 + \beta_1*Enrollment + \beta_2*Percent.Asian 
+ \beta_3*Percent.Black + \beta_4*Economic.Need.Index + 
\beta_5*Principal.Experience.yrs + \beta_6*Teachers.Rating.pct
$$

### Probabilistic Conclusions for shiny
```{r}
glm.coef = coef(glm.fit.model)
glm.coef

#Function to display probability
logit2prob <- function(logit){
  odds <- exp(logit)
  prob <- odds / (1 + odds)
  return(prob)
}
```

### Visualizations (R Shiny)

```{r}
ui <- fluidPage(
    title = "NYC High School Performance",
    titlePanel("NYC High School Performance"),
    sidebarLayout(
      sidebarPanel = sidebarPanel(
        h4("Viewable Statistics"),
        helpText("View how changing school parameters affects whether it does or doesn't meet standards"),
        selectInput("selection", "Select something", choices = c("School Size", "Race - Asian", "Race - Black", "Economic Need Index", "Principal Experience", "Instruction Rating")),
        conditionalPanel(
          "input.selection == 'School Size'",
          sliderInput("slider_enrollment", "Enrollment", min = min(data5$Enrollment), max = max(data5$Enrollment), value = 100, ticks = FALSE)
        ),
        conditionalPanel(
          "input.selection == 'Race - Asian'",
          sliderInput("slider_asian", "Asian Percentage", min = min(data5$Percent.Asian), max = max(data5$Percent.Asian), value = 50, ticks = FALSE)
        ),
        conditionalPanel(
          "input.selection == 'Race - Black'",
          sliderInput("slider_black", "Black Percentage", min = min(data5$Percent.Black), max = max(data5$Percent.Black), value = 50, ticks = FALSE)
        ),
        conditionalPanel(
          "input.selection == 'Economic Need Index'",
          sliderInput("slider_economic", "Economic Need Index", min = min(data5$Economic.Need.Index), max = max(data5$Economic.Need.Index), value = .5, ticks = FALSE)
        ),
        conditionalPanel(
          "input.selection == 'Principal Experience'",
          sliderInput("slider_principal", "Principal Experience", min = min(data5$Principal.Experience.yrs), max = max(data5$Principal.Experience.yrs), value = .5, ticks = FALSE)
        ),
        conditionalPanel(
          "input.selection == 'Instruction Rating'",
          sliderInput("slider_instruction", "% Approval of Instruction", min = min(data5$Instruction.Rating.pct), max = max(data5$Instruction.Rating.pct), value = .5, ticks = FALSE)
        )
      ),
      mainPanel = mainPanel(
        textOutput("selected_var"),
        conditionalPanel(
        condition = "input.selection == 'School Size'",
        textOutput("probability_enrollment")
        ),
        conditionalPanel(
        condition = "input.selection == 'Race - Asian'",
        textOutput("probability_asian")
        ),
        conditionalPanel(
        condition = "input.selection == 'Race - Black'",
        textOutput("probability_black")
        ),
        conditionalPanel(
        condition = "input.selection == 'Principal Experience'",
        textOutput("probability_principal")
        ),
        conditionalPanel(
        condition = "input.selection == 'Economic Need Index'",
        textOutput("probability_economic")
        ),
        conditionalPanel(
        condition = "input.selection == 'Instruction Rating'",
        textOutput("probability_instruction")
        ),
        conditionalPanel(
        condition = "input.selection == 'School Size'",
        plotOutput("enrollment_plot")
        ),
        conditionalPanel(
        condition = "input.selection == 'Race - Asian'",
        plotOutput("asian_plot")
        ),
        conditionalPanel(
        condition = "input.selection == 'Race - Black'",
        plotOutput("black_plot")
        ),
        conditionalPanel(
        condition = "input.selection == 'Principal Experience'",
        plotOutput("principal_plot")
        ),
        conditionalPanel(
        condition = "input.selection == 'Economic Need Index'",
        plotOutput("economic_plot")
        ),
        conditionalPanel(
        condition = "input.selection == 'Instruction Rating'",
        plotOutput("instruction_plot")
        ),
        textOutput("plot_explanation")
      )
    )
)
server <- function(input, output) {
  output$selected_var <- renderText({ 
    paste("You have selected", input$selection)
  })
  output$probability_enrollment <- renderText({ 
    paste("Holding all else equal, this school has a probability of meeting the target of", logit2prob(glm.coef["(Intercept)"] + input$slider_enrollment * glm.coef["Enrollment"]))
  })
  output$probability_asian <- renderText({ 
    paste("Holding all else equal, this school has a probability of meeting the target of", logit2prob(glm.coef["(Intercept)"] + input$slider_asian * glm.coef["Percent.Asian"]))
  })
  output$probability_black <- renderText({ 
    paste("Holding all else equal, this school has a probability of meeting the target of", logit2prob(glm.coef["(Intercept)"] + input$slider_black * glm.coef["Percent.Black"]))
  })
  output$probability_principal <- renderText({ 
    paste("Holding all else equal, this school has a probability of meeting the target of", logit2prob(glm.coef["(Intercept)"] + input$slider_principal * glm.coef["Principal.Experience.yrs"]))
  })
  output$probability_economic <- renderText({ 
    paste("Holding all else equal, this school has a probability of meeting the target of", logit2prob(glm.coef["(Intercept)"] + input$slider_economic * glm.coef["Economic.Need.Index"]))
  })
  output$probability_instruction <- renderText({ 
    paste("Holding all else equal, this school has a probability of meeting the target of", logit2prob(glm.coef["(Intercept)"] + input$slider_instruction * glm.coef["Teachers.Rating.pct"]))
  })
  output$enrollment_plot <- renderPlot(p_enrollment + geom_vline(aes(xintercept = input$slider_enrollment), colour = "blue", size = 1))
  output$asian_plot <- renderPlot(p_asian + geom_vline(aes(xintercept = input$slider_asian), colour = "blue", size = 1))
  output$black_plot <- renderPlot(p_black + geom_vline(aes(xintercept = input$slider_black), colour = "blue", size = 1))
  output$principal_plot <- renderPlot(p_principal_exp + geom_vline(aes(xintercept = input$slider_principal), colour = "blue", size = 1))
  output$economic_plot <- renderPlot(p_econ + geom_vline(aes(xintercept = input$slider_economic), colour = "blue", size = 1))
  output$instruction_plot <- renderPlot(p_instruction_rating + geom_vline(aes(xintercept = input$slider_instruction), colour = "blue", size = 1))
  output$plot_explanation <- renderText({
    paste("This plot compares the distribution of schools that have met versus not met the target with respect to the parameter chosen. The blue vertical line indicates the parameter level that you have indicated.")
  })
}
shinyApp(ui, server)
```





### Conclusions

### To Do

Questions
- How to scrape data?
- Bind two data sets?




