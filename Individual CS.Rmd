---
title: "Individual CS"
author: "Austin Jia"
date: "11/28/2019"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### Libraries

```{r, echo = FALSE, include = FALSE}
# Installing packages
pkgTest <- function(x) {
  if (!require(x,character.only = TRUE)) {
    install.packages(x,dep=TRUE)
  }
}
pkgs <- c("jsonlite", "dplyr", "rvest", "purrr", "ggplot2", "gganimate", "ggthemes", "lubridate", "zoo", "shiny", "stringr", "mice", "VIM", "parallel", "corrplot", "MASS", "caTools", "nnet", "randomForest", "pROC", "caret", "ggpubr")
for (pkg in pkgs) {
  pkgTest(pkg)
}
```

```{r, include=FALSE, echo = FALSE}
library(jsonlite)
library(dplyr)
library(rvest)
library(purrr)
library(ggplot2)
library(gganimate)
library(ggthemes)
library(lubridate)
library(zoo)
library(shiny)
library(stringr)
library(mice)
library(VIM)
library(parallel)
library(corrplot)
library(MASS)
library(caTools)
library(nnet)
library(randomForest)
library(pROC)
library(caret)
library(ggpubr)
```

### Scraping
### Page by page method

```{r}
base_url = "https://data.cityofnewyork.us/Education/2016-2017-School-Quality-Report-Elem-Middle-K-8-Sc/9n2i-9h9s/data"
p = read_html(base_url)

school_quality = tibble(
  "Student Achievement Rating" = p %>%
    html_nodes("td:nth-child(11) div") %>%
    html_text()
) 
school_quality
```




### Yellow Pages Method

```{r}
count = 0

for(numPage in 1:2){

        # Create and read the page address
        page = paste('https://data.cityofnewyork.us/Education/2016-2017-School-Quality-Report-Elem-Middle-K-8-Sc/9n2i-9h9s/data/?page', '=', numPage)
        nPage <- str_replace_all(page, pattern=" ", repl="")

        # Read the 20 items of each the page
        for(numItem in 1:3){

                print(paste(' -- Reading the item', numItem, ' on page', numPage))

                item =  paste('item', numItem, sep = "", collapse = NULL)
                xPath <- paste("//*[@id=',item, ']", sep = "'", collapse = NULL)

                # read the path
                readPath <- nPage %>% read_html() %>% html_nodes(xpath = xPath)

                # Get values
                student_achievement_rating  <- readPath %>% html_nodes(".table-responsive:nth-child(7) td:nth-child(11) div") %>% html_text(trim = TRUE)
                
                print(student_achievement_rating)
                
                lengthStudentachievementrating <- length(student_achievement_rating)
                
                print(lengthStudentachievementrating)

                enrollment <- readPath %>% html_nodes("td:nth-child(4) div") %>% html_text(trim = TRUE)
                lengthEnrollment <- length(enrollment)

                school_type <- readPath %>% html_nodes("td:nth-child(3) div") %>% html_text(trim = TRUE)
                lengthSchooltype <- length(school_type)

                if(lengthStudentachievementrating == 0){

                        student_achievement_rating = 'NA'

                }

                if(lengthEnrollment == 0){

                        enrollment = 'NA'

                }

                if(lengthSchooltype == 0){

                        school_type = 'NA'

                }

                # Store variables
                if(count == 0){

                        vectorStudentachievementrating <- student_achievement_rating
                        vectorEnrollment <- enrollment
                        vectorSchooltype <- school_type
                }else{

                        vectorStudentachievementrating <- c(vectorStudentachievementrating, student_achievement_rating)
                        vectorEnrollment <- c(vectorEnrollment, enrollment)
                        vectorSchooltype <- c(vectorSchooltype, school_type)

                }


                count = count + 1

        }


}


df <- data.frame(vectorStudentachievementrating, vectorEnrollment, vectorSchooltype)

df
```

### Data Cleaning

```{r}
data <- read.csv("schooldata.csv")
colnames(data)

#Renaming variable names
data = data %>% 
  rename(
    Instruction.Rating = Rigorous.Instruction.Rating,
    Teachers.Rating = Collaborative.Teachers.Rating,
    Leadership.Rating = Effective.School.Leadership.Rating,
    Community.Ties.Rating = Strong.Family.Community.Ties.Rating,
    Instruction.Rating.pct = Rigorous.Instruction...Percent.Positive,
    Teachers.Rating.pct = Collaborative.Teachers...Percent.Positive,
    Supportive.Environment.pct = Supportive.Environment...Percent.Positive,
    Leadership.Rating.pct = Effective.School.Leadership...Percent.Positive,
    Community.Ties.Rating.pct = Strong.Family.Community.Ties...Percent.Positive,
    Challenging.Curriculum.qr = Quality.Review...How.interesting.and.challenging.is.the.curriculum.,
    Effective.Teaching.qr = Quality.Review...How.effective.is.the.teaching.and.learning.,
    School.Assess.qr = Quality.Review...How.well.does.the.school.assess.what.students.are.learning.,
    Expectations.Communicated.qr = Quality.Review...How.clearly.are.high.expectations.communicated.to.students.and.staff.,
    Teachers.Cooperation.qr = Quality.Review...How.well.do.teachers.work.with.each.other.,
    Safe.Inclusive.qr = Quality.Review...How.safe.and.inclusive.is.the.school.while.supporting.social.emotional.growth.,
    Resource.Allocation.qr = Quality.Review...How.well.does.the.school.allocate.and.manage.resources.,
    Meet.Goals.qr = Quality.Review...How.well.does.the.school.identify..track..and.meet.its.goals.,
    Teacher.Development.qr = Quality.Review...How.thoughtful.is.the.school.s.approach.to.teacher.development.and.evaluation.,
    Decisions.Evaluated.qr = Quality.Review...How.well.are.school.decisions.evaluated.and.adjusted.,
    Review.Dates.qr = Quality.Review...Dates.of.Review,
    ELA.Proficiency = Average.Grade.8.English.Proficiency,
    Math.Proficiency = Average.Grade.8.Math.Proficiency,
    Principal.Experience.yrs = Years.of.principal.experience.at.this.school, 
    Teachers.3yrs.Experience = Percent.of.teachers.with.3.or.more.years.of.experience,
    Students.Chronically.Absent = Percent.of.Students.Chronically.Absent
    )
#

#Replacing blank levels with NAs
data <- data %>% mutate_if(is.factor, list(~factor(replace(., .=="", NA))))
```


```{r}
# Response Variable
data$Student.Achievement.Rating <- factor(data$Student.Achievement.Rating,levels = c("Not Meeting Target", "Approaching Target", "Meeting Target", "Exceeding Target", "NA"))

g1 = ggplot(data, aes(factor(Student.Achievement.Rating),fill = Student.Achievement.Rating)) +
geom_bar(stat="count", position = "dodge") + 
scale_fill_brewer(palette = "Set1") + ggtitle("Student Achievement Rating Distribution") + xlab("Student Achievement Rating") + labs(fill = "Target Category") + theme(axis.text.x=element_text(angle=45, hjust=1))

#Combining Factor Levels
levels(data$Student.Achievement.Rating) <- list("Meeting Target"=c("Meeting Target", "Exceeding Target"), "Not Meeting Target"=c("Not Meeting Target", "Approaching Target"))
```

I merged the four response categories of "Not Meeting Target", "Approaching Target", "Meeting Target", and "Exceeding Target" into a binary "Not Meeting Target" and "Meeting Target". I did this for a couple reasons. First, this simplifies the classification problem down from multinomial logistic regression to binary logistic regression, which features simpler interpretations. Second, "Not Meeting Target" only had 39 occurences; with so many predictors, my model would surely have low power. Finally, while it is nice to have a gradient of exceptional to mediocre schools, from a policymaker's perspective, it is more expedient to allocate a budget to all schools that fall below a certain threshold. 

```{r}
#Explanatory Variables

#Collinearity Matrix
data_numeric = data[ , purrr::map_lgl(data, is.numeric)]
corrplot(cor(data_numeric, use="pairwise.complete.obs"), method = "circle", tl.cex=0.5)

#Removing Covariates
redundant_cols = c("Instruction.Rating", "Supportive.Environment.Rating", "Community.Ties.Rating", "Teachers.Rating", "Leadership.Rating", "Trust.Rating", "DBN", "Percent.HRA.Eligible", "Effective.Teaching.qr", "Expectations.Communicated.qr", "Safe.Inclusive.qr", "Meet.Goals.qr", "Decisions.Evaluated.qr", "Challenging.Curriculum.qr", "School.Assess.qr", "Teachers.Cooperation.qr", "Resource.Allocation.qr", "Teacher.Development.qr", "Review.Dates.qr", "Students.Chronically.Absent", "Percent.in.Temp.Housing", "School.Type", "ELA.Proficiency", "Math.Proficiency")
data = data[ , -which(names(data) %in% redundant_cols)]
colnames(data)
```

I decided to remove the above covariates for a couple reasons. First, as the correlation matrix demonstrates, there is high correlation between several rating metrics and economic need proxies, so I eliminated all but one to address collinearity and reduce variance. For example, Supportive.Environment.Rating and Supportive.Environment.Rating.pct measure the same metric in different formats, and percent in temporary housing and percent HRA elgible are both proxies for economic need. Second, as the regression "one-in-ten" rule-of-thumb dictates, I should have at most one predictor for every 10 response-variable combinations. Third, I removed all the Quality Review covariates because (1) they are likely highly correlated with each other, (2) the data dictionary does not define what constitutes such subjective evaluation metrics, and (3) these metrics are likely highly inconsistent from school to school, so I felt that they did not add much value to the model.

### Missing Data

```{r}
sum(is.na(data)) / (dim(data)[1] * dim(data)[2])
nrow(data[complete.cases(data), ])
nrow(data[complete.cases(data), ])/nrow(data)
```

```{r}
missing.prop <- apply(data, MARGIN = 2, FUN = function(x) { sum(is.na(x)) })
missing.prop <- missing.prop / dim(data)[1]
missing.prop <- data.frame("prop" = missing.prop,
                           "var" = names(data))
ggplot(missing.prop, aes(x = reorder(var, -prop), y = prop)) + 
  geom_bar(stat = "identity") +
  theme(axis.text.x=element_text(angle=90,hjust=1,vjust=0.5)) + 
  geom_col(colour = "black", fill = "#FF6666") + 
  xlab("Covariate") + 
  ylab("Proportion Missing") +
  ggtitle("The Proportion of Missing Values for Each Covariate")

sum(is.na(data$Student.Achievement.Rating))/nrow(data)
```

Some initial data exploration tells us that our data is missing about 8% of its values. That 8% missing data is distributed in such a way that only 26% of our observations (336 schools) have complete information. The plot showcases some of the most problematic covariates in terms of missing data. 

We suspected that the Economic Need Index might have some effect on the presence of several key variables in the dataset. Firstly, we observed that there are no data points missing with the Year of Cardiac Catherization variable.Because we have no missing values of the Economic Need Index variable, margin plots will not make sense here because there will not exist a subset of the data for which the variable is missing. We will look at the distribution of present/missing data across time for the top 2 covariates with the largest missing proportion. 

```{r}
#Not MCAR
marginplot(data[, c("Teacher.Attendance.Rate", "Teachers.3yrs.Experience")], col = mdc(1:2), cex.numbers = 1.2, pch = 19)
```

Looking at the distributions, we can see that the missngness of Teacher Attendance and Teacher Experience seem dependent, indicating that the covariates are not MCAR. This could be because when teachers are absent during data collection days, then teacher experience may not be collected. 

While it would be nice to use multiple imputation mechanisms, it simply is not working right now.  

```{r, include=FALSE}
#Mean and Mode Imputation 

calc.mode <- function(x) {
  ux <- na.omit(unique(x))
  ux[which.max(tabulate(match(x, ux)))]
}
impute_covariates <- as.character(missing.prop[(missing.prop$prop <= 0.15) & (missing.prop$prop > 0), ]$var)
data2 <- as.data.frame(data)
for (var in impute_covariates) {
  print(var)
  if (is.factor(data2[[var]])) {
    data2[is.na(data2[[var]]), var] <- calc.mode(data2[[var]])
  } else {
    data2[is.na(data[[var]]), var] <- mean(data[[var]], na.rm = TRUE)
  }
}

colnames(data)[colSums(is.na(data)) > 0]
colnames(data2)[colSums(is.na(data2)) > 0]
```

We used MICE, or Multiple Imputation using Chained Equations, to created our imputed datasets. We created 4 imputed datasets, roughly corresponding to the percent of missing data. 

```{r, include=FALSE}
# Not working at the moment

# if (!file.exists("mice.rds")) {
#   start_time <- Sys.time()
#   data3 <- parlmice(data2, m=4, printFlag=FALSE, maxit = 4,
#                   cluster.seed=123, n.core = 2, n.imp.core = 2, cl.type = "FORK")
#   end_time <- Sys.time()
#   end_time - start_time
# } else {
#   data3 <- readRDS("mice.rds")
# }
# 
# missVars <- names(data2)[colSums(is.na(data2)) > 0]
# missVars
# 
# data_imputer = subset(data2, select = -c(School.Name, Teacher.Attendance.Rate))
# data_school_names = data2$School.Name
# 
# data3 <- mice(data_imputer, m=1, printFlag=TRUE, maxit = 1)
# 
# data3$loggedEvents
# 
# sum(is.na(data3$data))
```

### EDA - General

```{r}
#Response Variable
g2 = ggplot(data2, aes(factor(Student.Achievement.Rating),fill = Student.Achievement.Rating)) +
geom_bar(stat="count", position = "dodge") + 
scale_fill_brewer(palette = "Set1") + ggtitle("Student Achievement Rating Distribution") + xlab("Student Achievement Rating") + labs(fill = "Target Category") + theme(axis.text.x=element_text(angle=45, hjust=1))

#Racial Breakdown
g3 = ggplot(data2,aes(x=Percent.Asian,fill=factor(Student.Achievement.Rating)))+geom_density(alpha=0.25)+
  geom_vline(aes(xintercept=mean(Percent.Asian[Student.Achievement.Rating=="Not Meeting Target"],na.rm=T)),color="red",linetype="dashed",lwd=1)+
  geom_vline(aes(xintercept=mean(Percent.Asian[Student.Achievement.Rating=="Meeting Target"],na.rm=T)),color="green",linetype="dashed",lwd=1)+
  scale_x_continuous(breaks = seq(8,15,1))+
  xlab(label = "Percent Asian")+
  ggtitle("Distribution of Percentage Asian")+
  theme_classic() + labs(fill = "Student Achievement Rating")

g4 = ggplot(data2,aes(x=Percent.Hispanic,fill=factor(Student.Achievement.Rating)))+geom_density(alpha=0.25)+
  geom_vline(aes(xintercept=mean(Percent.Hispanic[Student.Achievement.Rating=="Not Meeting Target"],na.rm=T)),color="red",linetype="dashed",lwd=1)+
  geom_vline(aes(xintercept=mean(Percent.Hispanic[Student.Achievement.Rating=="Meeting Target"],na.rm=T)),color="green",linetype="dashed",lwd=1)+
  scale_x_continuous(breaks = seq(8,15,1))+
  xlab(label = "Percent Hispanic")+
  ggtitle("Distribution of Percentage Hispanic")+
  theme_classic()+ labs(fill = "Student Achievement Rating")

g5 = ggplot(data2,aes(x=Percent.Black,fill=factor(Student.Achievement.Rating)))+geom_density(alpha=0.25)+
  geom_vline(aes(xintercept=mean(Percent.Black[Student.Achievement.Rating=="Not Meeting Target"],na.rm=T)),color="red",linetype="dashed",lwd=1)+
  geom_vline(aes(xintercept=mean(Percent.Black[Student.Achievement.Rating=="Meeting Target"],na.rm=T)),color="green",linetype="dashed",lwd=1)+
  scale_x_continuous(breaks = seq(8,15,1))+
  xlab(label = "Percent Black")+
  ggtitle("Distribution of Percentage Black")+
  theme_classic()+ labs(fill = "Student Achievement Rating")

g6 = ggplot(data2,aes(x=Percent.White,fill=factor(Student.Achievement.Rating)))+geom_density(alpha=0.25)+
  geom_vline(aes(xintercept=mean(Percent.White[Student.Achievement.Rating=="Not Meeting Target"],na.rm=T)),color="red",linetype="dashed",lwd=1)+
  geom_vline(aes(xintercept=mean(Percent.White[Student.Achievement.Rating=="Meeting Target"],na.rm=T)),color="green",linetype="dashed",lwd=1)+
  scale_x_continuous(breaks = seq(8,15,1))+
  xlab(label = "Percent Asian")+
  ggtitle("Distribution of Percentage Asian")+
  theme_classic()+ labs(fill = "Student Achievement Rating")

ggarrange(g3, g4, g5, g6, ncol=2, nrow=2)

#Faculty Experience
g7 = ggplot(data2,aes(x=Principal.Experience.yrs,fill=factor(Student.Achievement.Rating)))+geom_density(alpha=0.25)+
  geom_vline(aes(xintercept=mean(Principal.Experience.yrs[Student.Achievement.Rating=="Not Meeting Target"],na.rm=T)),color="red",linetype="dashed",lwd=1)+
  geom_vline(aes(xintercept=mean(Principal.Experience.yrs[Student.Achievement.Rating=="Meeting Target"],na.rm=T)),color="green",linetype="dashed",lwd=1)+
  scale_x_continuous(breaks = seq(8,15,1))+
  xlab(label = "Principal Experience (yrs)")+
  ggtitle("Distribution of Principal Experience")+
  theme_classic()+ labs(fill = "Student Achievement Rating")

g8 = ggplot(data2,aes(x=Teachers.3yrs.Experience,fill=factor(Student.Achievement.Rating)))+geom_density(alpha=0.25)+
  geom_vline(aes(xintercept=mean(Teachers.3yrs.Experience[Student.Achievement.Rating=="Not Meeting Target"],na.rm=T)),color="red",linetype="dashed",lwd=1)+
  geom_vline(aes(xintercept=mean(Teachers.3yrs.Experience[Student.Achievement.Rating=="Meeting Target"],na.rm=T)),color="green",linetype="dashed",lwd=1)+
  scale_x_continuous(breaks = seq(8,15,1))+
  xlab(label = "Teacher Experience (% More than 3 yrs)")+
  ggtitle("Distribution of Teacher Experience")+
  theme_classic()+ labs(fill = "Student Achievement Rating")

#Financial Circumstances
g9 = ggplot(data2,aes(x=Economic.Need.Index,fill=factor(Student.Achievement.Rating)))+geom_density(alpha=0.25)+
  geom_vline(aes(xintercept=mean(Economic.Need.Index[Student.Achievement.Rating=="Not Meeting Target"],na.rm=T)),color="red",linetype="dashed",lwd=1)+
  geom_vline(aes(xintercept=mean(Economic.Need.Index[Student.Achievement.Rating=="Meeting Target"],na.rm=T)),color="green",linetype="dashed",lwd=1)+
  scale_x_continuous(breaks = seq(8,15,1))+
  xlab(label = "Economic Need Index")+
  ggtitle("Distribution of Economic Need Index")+
  theme_classic()+ labs(fill = "Student Achievement Rating")
```


### Modeling

```{r}
# Split dataset into training set, validation set, and test set

splitSample <- sample(1:2, size = nrow(data2), prob = c(0.7, 0.3), 
    replace = T)

# training set
train_set <- na.omit(data2[splitSample == 1, ])  # 397 observations

intrain <- sample(1:2, size = nrow(train_set), prob = c(0.7, 0.3), replace = T)

train <- train_set[intrain == 1, ]  # 277 observations

# validation set
valid <- train_set[intrain == 2, ]  # 120 observations

# test set
test <- na.omit(data2[splitSample == 2, ])  # 172 observations

#Cross Validation method
cv <- trainControl(method = "cv", number = 10)
set.seed(1234)
```

```{R}
#Specifiying models

# Logisitic Regression
glm.fit <- train(Student.Achievement.Rating ~ Percent.Asian + Enrollment, data = train, method = "glm", family = binomial, 
    trControl = cv)
summary(glm.fit)
# Random Forest
rf.fit <- train(Student.Achievement.Rating ~ Percent.Asian + Enrollment + Economic.Need.Index, data = train, method = "rf", ntree = 100, 
    importance = TRUE, trControl = cv)
rf.fit.2 <- randomForest(Student.Achievement.Rating ~ Percent.Asian + Enrollment + Economic.Need.Index, data = train, ntree = 100, 
    importance = TRUE)
summary(rf.fit)
varImpPlot(rf.fit.2)
```

```{r}
#Predictions on Validation Set and Confusion Matrices

# Logistic Regression
pred.glm <- predict(glm.fit, valid)
# Random Forest
pred.rf <- predict(rf.fit, valid)

# Logisitic Regression
cm.glm <- confusionMatrix(valid$Student.Achievement.Rating, pred.glm)
# Random Forest
cm.rf <- confusionMatrix(valid$Student.Achievement.Rating, pred.rf)
```

```{r}
#Tabulating Results
Model <- c("Logistic regression", "Random forest")  # vector containing names of models

# Training classification accuracy
TrainAccuracy <- c(max(glm.fit$results$Accuracy), max(rf.fit$results$Accuracy))

# Training misclassification error
Train_missclass_Error <- 1 - TrainAccuracy

# validation classification accuracy
ValidationAccuracy <- c(cm.glm$overall[1], 
    cm.rf$overall[1])

# Validation misclassification error or out-of-sample-error
Validation_missclass_Error <- 1 - ValidationAccuracy

metrics <- data.frame(Model, TrainAccuracy, Train_missclass_Error, ValidationAccuracy, 
    Validation_missclass_Error)  # data frame with above metrics

knitr::kable(metrics, digits = 5)  # print table using kable() from knitr package

#Prediction on test set
pred.test.glm <- predict(glm.fit, test)
pred.test.glm
pred.test.rf <- predict(rf.fit, test)
pred.test.rf
```

### Model Selection

Misclassification error is 36% for logistic regression and 54% for random forest. The logistic regression is also easier to interpret. For these reasons, we move ahead with the logistic regression. 

### Model Specification

$$
\mbox{logit}(Pr(y_i = 1)) = \beta_0 + \alpha^{race}_{j[i]} + \beta_1year_{[i]} + \alpha^{county}_{k[i]} + \epsilon_i \\
\alpha^{race}_j \mbox{~} N(\mu_{\alpha}, \sigma^2_{race}) \\
\alpha^{county}_k \mbox{~} N(\gamma_{\alpha}, \sigma^2_{county})
$$

### Visualizaitons (R Shiny)

### Conclusions

### To Do

Questions
- How to scrape data?
- MICE not working?




